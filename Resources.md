# Resources on Transformer Data Preparation, Trainng, and Fine-tuning 

## Common Articles: repos, online materials, videos

HuggingFace notebook examples: 

  https://github.com/huggingface/notebooks/blob/main/examples

### BERT fine-tuning

[Python Tutorial to Fine-tune SBERT BI-Encoder with Domain-specific Training Dataset, Discover AI, youtube video, 2023](https://youtu.be/FidMAm-tj9k?si=oED-7avcJFsMrLyv)

[Fine-Tune SBERT on specific Knowledge Domain with Cross-Encoder Sentence Transformers, Discover AI, youtube video, 2023](https://youtu.be/JxfS5ZjdxGE?si=a87k5dtQzQu1qTu8)

[Fine-Tuning BERT for Text Classification (with Example Code), Shaw Talebi, 2024](https://youtu.be/4QHg8Ix8WWQ?si=DkQyws-ZPtiOJ5zS)

  repo for the Phishing classification example: https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/model-compression

  model for the Phishing classification example: https://huggingface.co/shawhin/bert-phishing-classifier_teacher

  dataset for the Phishing classification example: https://huggingface.co/datasets/shawhin/phishing-site-classification

[Universal Language Model Fine-tuning for Text Classification, Jeremy Howard, Sebastian Rudder, FastAI, 2018](https://github.com/dimitarpg13/transformer_finetuning/blob/main/articles/Universal_Language_Model_Fine-tuning_for_Text_Classification_Howard_2018.pdf)

[Semi-supervised Sequence Learning, A Dai, Quoc V. Le, Google, 2015](https://github.com/dimitarpg13/transformer_finetuning/blob/main/articles/Semi-supervised_Sequence_Learning_Dai_2015.pdf)

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, J. Devlin et al, 2019](https://github.com/dimitarpg13/transformer_finetuning/blob/main/articles/bert/BERT-Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding_Devlin_2019.pdf)

## Tokenization

HuggingFace notebook example: 

  https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb 


### Byte-Pair Encoding

[Let's build the GPT Tokenizer, Andrej Karpathy, 2024](https://youtu.be/zduSFxRajkE?si=AOUNH7lcQiZH5FeV)

  Supplementary links:

  Google colab for the video: https://colab.research.google.com/drive/1y0KnCFZvGVf_odSfcNAws6kcDD7HsI0L?usp=sharing

  GitHub repo for the video: minBPE: https://github.com/karpathy/minbpe

  tiktokenizer: https://tiktokenizer.vercel.app
  
  tiktoken from OpenAI: https://github.com/openai/tiktoken
  
  sentencepiece from Google: https://github.com/google/sentencepiece


## Embeddings


## Fine-tuning a pretrained model

HuggingFace notebook example on training: 

  https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb

HuggingFace notebook example on fine-tunning for classification: 

  https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb

HuggingFace notebook example on fine-tuning for question-answering:

  https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb


